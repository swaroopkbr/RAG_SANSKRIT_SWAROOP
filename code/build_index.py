import faiss
import numpy as np
import pickle
from sentence_transformers import SentenceTransformer

from ingest import load_documents
from preprocess import chunk_documents


MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"


def build_faiss_index():
    
    """Sanskrit Docs â†’ Chunking â†’ Embeddings â†’ FAISS Index"""

    print("\nðŸ“Œ Loading Documents...")
    documents = load_documents()

    print("ðŸ“Œ Chunking Sanskrit Text...")
    chunks = chunk_documents(documents)

    print("ðŸ“Œ Loading Embedding Model (CPU)...")
    embedder = SentenceTransformer(MODEL_NAME)

    print("ðŸ“Œ Creating Chunk Embeddings...")
    embeddings = embedder.encode(chunks)
    embeddings = np.array(embeddings).astype("float32")

    print("ðŸ“Œ Building FAISS Vector Index...")
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)

    # Save index
    faiss.write_index(index, "faiss_index.idx")

    # Save chunks
    with open("chunks.pkl", "wb") as f:
        pickle.dump(chunks, f)

    print("\nâœ… Index Built Successfully!")
    print("âœ… Total Chunks:", len(chunks))


if __name__ == "__main__":
    build_faiss_index()
